{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "#Initial script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdata():\n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "    print('Shape of train: {}'.format(train.shape))\n",
    "    test = pd.read_csv(\"test.csv\")\n",
    "    print('Shape of test: {}'.format(test.shape))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata():\n",
    "    train, test = readdata()\n",
    "    print(\"Preparing data....\")\n",
    "    print(\"Log-transforming target....\")\n",
    "    train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "    \n",
    "    print(\"Combining datasets...\")\n",
    "    trainrow = train.shape[0]\n",
    "    testrow = test.shape[0]\n",
    "    \n",
    "    train_ID = train['Id']\n",
    "    test_ID = test['Id']\n",
    "    train.drop('Id', axis=1, inplace=True)\n",
    "    test.drop('Id', axis = 1, inplace = True)\n",
    "    \n",
    "    print(\"Saving target...\")\n",
    "    target = train.SalePrice.values\n",
    "    \n",
    "    all_data = pd.concat((train,test)).reset_index(drop=True)\n",
    "    all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Combined datasize is : {}\".format(all_data.shape))\n",
    "    \n",
    "    print(\"Filling Categorical NA's...\")\n",
    "    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'SaleType','MiscFeature', 'Alley',\n",
    "            'BsmtExposure', 'BsmtCond','BsmtFinType2', 'BsmtFinType1', 'MasVnrType','MSZoning', 'PoolQC', 'Fence', 'FireplaceQu'):\n",
    "        all_data[col] = all_data[col].fillna('Unknown')\n",
    "        \n",
    "    print(\"Filling Numerical NA's...\")\n",
    "    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea', 'BsmtHalfBath', 'BsmtFullBath', 'BsmtFinSF1',\n",
    "           'BsmtFinSF1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF2'):\n",
    "            all_data[col] = all_data[col].fillna(0)\n",
    "    \n",
    "    print(\"Imputing with median...\")\n",
    "    all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    print(\"Imputing with mode...\")\n",
    "    all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "    all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "    all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "    all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "    all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "    \n",
    "    print(\"Dropping features...\")\n",
    "    all_data = all_data.drop(['Utilities'], axis=1)\n",
    "    \n",
    "    print(\"Labelencoding Categorical Features...\")\n",
    "    catcols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "    for c in catcols:\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(all_data[c].values)) \n",
    "        all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "        \n",
    "    print(\"One-hot Encoding Categorical Variables...\")\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "        \n",
    "        \n",
    "    print('Final shape of dataset: {}'.format(all_data.shape))\n",
    "    print(\"Splitting dataset and returning train, test and target...\")\n",
    "    train = all_data[:trainrow] \n",
    "    test = all_data[trainrow:]\n",
    "    \n",
    "    return train, test, target, test_ID\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BayesXGB():\n",
    "    print(\"Performing Bayesian Optimization on XGB...\")\n",
    "    xgb_bo = BayesianOptimization(xgb_evaluate,{'max_depth'       : (3,15),\n",
    "                                                 'gamma'           : (0,5),\n",
    "                                                'colsample_bytree' : (0.3, 0.9),\n",
    "                                                'min_child_weight' : (0,25),\n",
    "                                                 'subsample'       : (0.5, 1),\n",
    "                                                 'alpha'           : (0, 5)\n",
    "                                            })\n",
    "    xgb_bo.maximize(init_points=10, n_iter=50, acq = 'ei')\n",
    "    print(\"Identified optimal hyperparameters...\")\n",
    "    print('Maximum value obtained: {}'.format(xgb_bo.res['max']['max_val']))\n",
    "    print(xgb_bo.res['max']['max_params'])\n",
    "    params = (xgb_bo.res['max']['max_params'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_child_weight'] = int(params['min_child_weight'])\n",
    "    params['silent'] = 1\n",
    "    params['eta'] = 0.01\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, gamma, colsample_bytree, min_child_weight, subsample, alpha):\n",
    "    dtrain =xgb.DMatrix(train, label=target)\n",
    "    params = {\n",
    "        'eval_metric' : 'rmse',\n",
    "        'max_depth'   : int(max_depth),\n",
    "        'subsample'   : max(min(subsample,1),0) ,\n",
    "        'eta'         : 0.01 ,\n",
    "        'gamma'       : max(gamma,0),\n",
    "        'alpha'       : max(alpha, 0),\n",
    "        'colsample_bytree' : max(min(colsample_bytree,1),0),\n",
    "        'min_child_weight' : int(min_child_weight),\n",
    "        'silent' : 1\n",
    "    }\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round = 2000, early_stopping_rounds = 100, nfold=5)\n",
    "    #BayesOptimization kan kun maximere og ikke minimere, derfor skal vi g√∏re RMSE negativt\n",
    "    return -1 * cv_result['test-rmse-mean'].iloc[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainxgb(params):\n",
    "    print(\"Training XGBoost with found parameters...\")\n",
    "    n_iters = 5\n",
    "    xgb_preds = []\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20, random_state = i)\n",
    "    \n",
    "        dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "        dvalid = xgb.DMatrix(X_test, label = y_test)\n",
    "        testxgb   = xgb.DMatrix(test)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "    \n",
    "        xgb_model = xgb.train(params, dtrain, 5000, watchlist, early_stopping_rounds = 150, verbose_eval = 500)\n",
    "        preds = xgb_model.predict(testxgb)\n",
    "        preds = np.exp(preds) - 1\n",
    "        xgb_preds.append(preds)\n",
    "        \n",
    "    #predictions = pd.DataFrame(list(zip(np.mean(xgb_preds, axis=0))), columns=['xgbpreds'])\n",
    "    print(\"Finished training and predicting...\")\n",
    "    return np.mean(xgb_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(pred):\n",
    "    submissions = pd.DataFrame()\n",
    "    submissions['Id'] = test_ID\n",
    "    submissions['SalePrice'] = pred['xgbpreds']\n",
    "    submissions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_evaluate(num_leaves, feature_fraction, bagging_fraction, max_depth, lambda_l1, lambda_l2, min_split_gain, min_child_weight):\n",
    "    dtrain =lgb.Dataset(train, label=target)\n",
    "    params = {'application':'regression_l2','num_iterations':2000, 'learning_rate':0.01, 'early_stopping_round':100, 'metric':'rmse', 'silent':1}\n",
    "    params[\"num_leaves\"] = int(num_leaves)\n",
    "    params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n",
    "    params['bagging_fraction'] = max(min(bagging_fraction, 1), 0)\n",
    "    params['max_depth'] = int(max_depth)\n",
    "    params['lambda_l1'] = max(lambda_l1, 0)\n",
    "    params['lambda_l2'] = max(lambda_l2, 0)\n",
    "    params['min_split_gain'] = min_split_gain\n",
    "    params['min_child_weight'] = min_child_weight\n",
    "    cv_result = lgb.cv(params, dtrain, nfold=5, stratified=False, metrics=['rmse'])\n",
    "    return -1 * cv_result['rmse-mean'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbBayes():\n",
    "    print(\"Performing Bayesian Optimization on LGB...\")\n",
    "    lgb_bo = BayesianOptimization(lgb_evaluate, {'num_leaves' : (3,25),\n",
    "                                                 'feature_fraction' : (0.1, 0.9),\n",
    "                                                 'bagging_fraction' : (0.1, 0.9),\n",
    "                                                 'max_depth'        : (3, 15),\n",
    "                                                 'lambda_l1'        : (0, 5),\n",
    "                                                 'lambda_l2'        : (0, 3),\n",
    "                                                 'min_split_gain'   : (0.001, 0.1),\n",
    "                                                 'min_child_weight' : (1, 25)    \n",
    "                                                })\n",
    "    lgb_bo.maximize(init_points=10, n_iter=50, acq ='ei')\n",
    "    print(\"Identified optimal hyperparameters...\")\n",
    "    print(\"Maximum value obtained: {}\".format(lgb_bo.res['max']['max_val']))\n",
    "    print(lgb_bo.res['max']['max_params'])\n",
    "    params = (lgb_bo.res['max']['max_params'])\n",
    "    params['num_leaves'] = int(params['num_leaves']) \n",
    "    params['min_child_weight'] = int(params['min_child_weight'])\n",
    "    params['max_depth'] = int(params['max_depth']) \n",
    "    params['metric'] = 'rmse'\n",
    "    params['learning_rate'] = 0.01\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainlgb(params):\n",
    "    print(\"Training LightGBM with found parameters...\")\n",
    "    n_iters = 5\n",
    "    lgb_preds = []\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20, random_state = i)\n",
    "    \n",
    "        dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "        dvalid = lgb.Dataset(X_test, label=y_test, reference=dtrain)\n",
    "            \n",
    "        lgb_model = lgb.train(params, dtrain, 5000, valid_sets=dvalid, early_stopping_rounds = 150, verbose_eval = 500)\n",
    "        preds = lgb_model.predict(test)\n",
    "        preds = np.exp(preds) - 1\n",
    "        lgb_preds.append(preds)\n",
    "        \n",
    "    #predictions = pd.DataFrame(list(zip(np.mean(lgb_preds, axis=0))), columns=['lgbpreds'])\n",
    "    print(\"Finished training and predicting...\")\n",
    "    return np.mean(lgb_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combinepreds(lgb_preds, xgb_preds):\n",
    "    preds = pd.DataFrame(np.column_stack([lgb_preds, xgb_preds]), \n",
    "                               columns=['LGB Preds', 'XGB Preds'])\n",
    "    preds['mean'] = preds.mean(axis=1)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(lgb_preds, xgb_preds):\n",
    "    pred = combinepreds(lgb_preds, xgb_preds)\n",
    "    submissions = pd.DataFrame()\n",
    "    submissions['Id'] = test_ID\n",
    "    submissions['SalePrice'] = pred['mean']\n",
    "    submissions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test, target, test_ID = preparedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = BayesXGB()\n",
    "xgbpreds = trainxgb(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = lgbBayes()\n",
    "lgbpreds = trainlgb(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(lgbpreds, xgbpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (1460, 81)\n",
      "Shape of test: (1459, 80)\n",
      "Preparing data....\n",
      "Log-transforming target....\n",
      "Combining datasets...\n",
      "Saving target...\n",
      "Combined datasize is : (2919, 79)\n",
      "Filling Categorical NA's...\n",
      "Filling Numerical NA's...\n",
      "Imputing with median...\n",
      "Imputing with mode...\n",
      "Dropping features...\n",
      "Labelencoding Categorical Features...\n",
      "One-hot Encoding Categorical Variables...\n",
      "Final shape of dataset: (2919, 223)\n",
      "Splitting dataset and returning train, test and target...\n"
     ]
    }
   ],
   "source": [
    "train, test, target, test_ID = preparedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Bayesian Optimization on XGB...\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 00m58s | \u001b[35m  -0.16914\u001b[0m | \u001b[32m   1.8731\u001b[0m | \u001b[32m            0.4734\u001b[0m | \u001b[32m   1.6143\u001b[0m | \u001b[32m     6.9588\u001b[0m | \u001b[32m           19.8711\u001b[0m | \u001b[32m     0.6138\u001b[0m | \n",
      "    2 | 00m45s |   -0.19394 |    4.1035 |             0.4574 |    3.6991 |      7.1551 |             6.7040 |      0.9706 | \n",
      "    3 | 01m14s | \u001b[35m  -0.16686\u001b[0m | \u001b[32m   2.3092\u001b[0m | \u001b[32m            0.5242\u001b[0m | \u001b[32m   1.6011\u001b[0m | \u001b[32m     7.3190\u001b[0m | \u001b[32m           13.9814\u001b[0m | \u001b[32m     0.8360\u001b[0m | \n",
      "    4 | 01m39s |   -0.18881 |    2.4176 |             0.8304 |    3.4421 |     11.8612 |             5.1439 |      0.9308 | \n",
      "    5 | 00m51s |   -0.18837 |    2.7026 |             0.6181 |    3.2795 |      5.2400 |             0.7352 |      0.9886 | \n",
      "    6 | 01m44s |   -0.18944 |    1.0590 |             0.6788 |    3.5796 |      9.1575 |            19.0820 |      0.7598 | \n",
      "    7 | 01m13s | \u001b[35m  -0.12976\u001b[0m | \u001b[32m   2.6034\u001b[0m | \u001b[32m            0.4672\u001b[0m | \u001b[32m   0.0167\u001b[0m | \u001b[32m    10.7259\u001b[0m | \u001b[32m           23.6169\u001b[0m | \u001b[32m     0.8757\u001b[0m | \n",
      "    8 | 01m10s |   -0.16996 |    1.5556 |             0.3174 |    1.8362 |     13.0884 |            15.5617 |      0.9982 | \n",
      "    9 | 01m24s |   -0.20597 |    4.5359 |             0.8207 |    3.8183 |      7.7071 |            15.7316 |      0.5557 | \n",
      "   10 | 01m50s |   -0.20771 |    2.2261 |             0.5279 |    4.9208 |     14.8876 |             2.6957 |      0.6937 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "   11 | 01m05s | \u001b[35m  -0.12311\u001b[0m | \u001b[32m   0.0235\u001b[0m | \u001b[32m            0.3624\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m    14.9474\u001b[0m | \u001b[32m           24.9760\u001b[0m | \u001b[32m     0.5167\u001b[0m | \n",
      "   12 | 02m05s |   -0.12603 |    1.0084 |             0.8551 |    0.0292 |     14.9979 |            24.4547 |      0.8784 | \n",
      "   13 | 01m00s |   -0.13289 |    2.6895 |             0.3596 |    0.0381 |     14.6882 |            24.9818 |      0.9874 | \n",
      "   14 | 02m32s |   -0.12485 |    0.0099 |             0.8616 |    0.0503 |     12.9558 |            24.8711 |      0.9739 | \n",
      "   15 | 01m28s |   -0.13918 |    4.6355 |             0.4617 |    0.0010 |     14.4580 |             0.0416 |      0.5759 | \n",
      "   16 | 01m46s |   -0.12461 |    0.4740 |             0.7111 |    0.0129 |     11.7915 |            24.4311 |      0.5376 | \n",
      "   17 | 04m38s | \u001b[35m  -0.12299\u001b[0m | \u001b[32m   0.2870\u001b[0m | \u001b[32m            0.7974\u001b[0m | \u001b[32m   0.0135\u001b[0m | \u001b[32m    14.1742\u001b[0m | \u001b[32m            0.9168\u001b[0m | \u001b[32m     0.6118\u001b[0m | \n",
      "   18 | 02m32s | \u001b[35m  -0.12252\u001b[0m | \u001b[32m   0.2599\u001b[0m | \u001b[32m            0.4494\u001b[0m | \u001b[32m   0.0066\u001b[0m | \u001b[32m    11.1673\u001b[0m | \u001b[32m            0.2540\u001b[0m | \u001b[32m     0.8964\u001b[0m | \n",
      "   19 | 01m34s | \u001b[35m  -0.12086\u001b[0m | \u001b[32m   0.0247\u001b[0m | \u001b[32m            0.3687\u001b[0m | \u001b[32m   0.0405\u001b[0m | \u001b[32m     9.6566\u001b[0m | \u001b[32m            3.4170\u001b[0m | \u001b[32m     0.5272\u001b[0m | \n",
      "   20 | 01m04s |   -0.13791 |    4.7734 |             0.6338 |    0.0389 |      3.7883 |             5.3561 |      0.7126 | \n",
      "   21 | 02m42s |   -0.12181 |    0.2917 |             0.8695 |    0.0090 |      8.8398 |             0.5133 |      0.6244 | \n",
      "   22 | 02m32s | \u001b[35m  -0.12014\u001b[0m | \u001b[32m   0.0694\u001b[0m | \u001b[32m            0.3116\u001b[0m | \u001b[32m   0.0444\u001b[0m | \u001b[32m    12.2268\u001b[0m | \u001b[32m            0.2920\u001b[0m | \u001b[32m     0.6191\u001b[0m | \n",
      "   23 | 02m03s |   -0.12143 |    0.1648 |             0.4823 |    0.0040 |     10.5293 |             0.3602 |      0.5426 | \n",
      "   24 | 00m33s |   -0.12090 |    0.1600 |             0.3429 |    0.0099 |      3.2446 |             4.4530 |      0.6720 | \n",
      "   25 | 01m21s |   -0.12101 |    0.1233 |             0.6227 |    0.0178 |      6.1738 |             2.9198 |      0.5744 | \n",
      "   26 | 00m58s |   -0.12738 |    0.0908 |             0.8269 |    0.1281 |      3.1862 |             0.9032 |      0.7609 | \n",
      "   27 | 00m59s |   -0.12628 |    0.0566 |             0.6646 |    0.0992 |      4.2493 |             7.3747 |      0.8876 | \n",
      "   28 | 02m04s |   -0.12356 |    0.0292 |             0.4298 |    0.0669 |     13.9969 |            21.2462 |      0.6101 | \n",
      "   29 | 03m30s |   -0.12176 |    0.0342 |             0.3126 |    0.0514 |     14.5211 |             0.0036 |      0.8833 | \n",
      "   30 | 02m30s |   -0.12094 |    0.0267 |             0.4506 |    0.0080 |     12.7884 |             1.4691 |      0.6007 | \n",
      "   31 | 01m43s |   -0.12461 |    0.0706 |             0.8516 |    0.0678 |      4.2139 |             4.5385 |      0.8289 | \n",
      "   32 | 00m51s |   -0.14317 |    4.9297 |             0.3852 |    0.1226 |      4.1238 |            24.8850 |      0.9465 | \n",
      "   33 | 01m37s |   -0.12174 |    0.1151 |             0.6586 |    0.0220 |      7.9449 |             8.0906 |      0.5300 | \n",
      "   34 | 00m33s |   -0.12163 |    0.2532 |             0.3553 |    0.0057 |      3.2887 |             5.7328 |      0.5604 | \n",
      "   35 | 02m56s |   -0.12053 |    0.0919 |             0.5414 |    0.0302 |     13.7075 |             0.1070 |      0.5599 | \n",
      "   36 | 01m12s |   -0.12016 |    0.1217 |             0.3190 |    0.0000 |      8.9342 |             3.9457 |      0.5000 | \n",
      "   37 | 02m38s | \u001b[35m  -0.11950\u001b[0m | \u001b[32m   0.0062\u001b[0m | \u001b[32m            0.4501\u001b[0m | \u001b[32m   0.0260\u001b[0m | \u001b[32m     8.2773\u001b[0m | \u001b[32m            0.3997\u001b[0m | \u001b[32m     0.5002\u001b[0m | \n",
      "   38 | 01m17s |   -0.14626 |    4.9516 |             0.7058 |    0.1225 |     10.3601 |            23.9734 |      0.5296 | \n",
      "   39 | 00m50s |   -0.12467 |    0.3123 |             0.7463 |    0.0339 |      3.4893 |            24.7967 |      0.7341 | \n",
      "   40 | 01m19s |   -0.12405 |    0.1371 |             0.5474 |    0.0425 |      7.2305 |            24.8615 |      0.9813 | \n",
      "   41 | 02m37s |   -0.12463 |    0.1552 |             0.6087 |    0.0623 |     14.9664 |             9.3866 |      0.8173 | \n",
      "   42 | 01m29s |   -0.12276 |    0.0743 |             0.3010 |    0.0218 |     11.1688 |            10.0387 |      0.9723 | \n",
      "   43 | 01m58s |   -0.12336 |    0.0334 |             0.5776 |    0.0111 |     13.3521 |             6.1859 |      0.5327 | \n",
      "   44 | 00m30s |   -0.12929 |    0.3476 |             0.3129 |    0.1282 |      3.0773 |            24.8919 |      0.8359 | \n",
      "   45 | 01m40s |   -0.12294 |    0.0043 |             0.5925 |    0.0334 |     14.9973 |            19.5913 |      0.5116 | \n",
      "   46 | 00m43s |   -0.12047 |    0.7511 |             0.3764 |    0.0063 |      4.8496 |             0.1779 |      0.5362 | \n",
      "   47 | 00m50s |   -0.14081 |    4.8968 |             0.8413 |    0.0344 |      3.5596 |             0.1616 |      0.6857 | \n",
      "   48 | 01m39s |   -0.12492 |    1.1579 |             0.3212 |    0.0269 |     13.3407 |             0.1960 |      0.5801 | \n",
      "   49 | 01m22s |   -0.12237 |    0.0929 |             0.3429 |    0.0202 |     14.8171 |            22.0273 |      0.6726 | \n",
      "   50 | 01m03s |   -0.12047 |    0.0184 |             0.4165 |    0.0044 |      6.1720 |             0.6158 |      0.8806 | \n",
      "   51 | 01m26s |   -0.12265 |    0.0712 |             0.6556 |    0.0079 |     12.4496 |            11.0247 |      0.5451 | \n",
      "   52 | 00m49s |   -0.12325 |    0.1686 |             0.8415 |    0.0028 |      3.0820 |            12.0626 |      0.7983 | \n",
      "   53 | 02m41s |   -0.12402 |    0.1120 |             0.8988 |    0.0324 |     10.5712 |             7.5634 |      0.9046 | \n",
      "   54 | 00m59s |   -0.12104 |    0.0445 |             0.3290 |    0.0216 |      8.8053 |            13.2447 |      0.5379 | \n",
      "   55 | 01m33s |   -0.12438 |    0.1545 |             0.8312 |    0.0136 |      9.2887 |            21.7318 |      0.9626 | \n",
      "   56 | 02m03s |   -0.12283 |    0.1121 |             0.8959 |    0.0120 |      7.2976 |            10.1471 |      0.7124 | \n",
      "   57 | 01m14s |   -0.12211 |    0.0136 |             0.6085 |    0.0224 |      5.8883 |            14.3548 |      0.7975 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   58 | 00m49s |   -0.12544 |    0.2156 |             0.8553 |    0.0329 |      3.0088 |            17.6853 |      0.9953 | \n",
      "   59 | 01m31s |   -0.12214 |    0.0113 |             0.3753 |    0.0160 |      8.8144 |            16.9244 |      0.8954 | \n",
      "   60 | 00m54s |   -0.12018 |    0.4105 |             0.3337 |    0.0045 |      6.5792 |             2.2545 |      0.5691 | \n",
      "Identified optimal hyperparameters...\n",
      "Maximum value obtained: -0.1195046\n",
      "{'max_depth': 8.27734097391035, 'gamma': 0.026024100201859635, 'colsample_bytree': 0.4500518255799414, 'min_child_weight': 0.39972572149608865, 'subsample': 0.5002013845312789, 'alpha': 0.006207801936168877}\n"
     ]
    }
   ],
   "source": [
    "params = BayesXGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBoost with found parameters...\n",
      "[0]\ttrain-rmse:11.4152\tvalid-rmse:11.4182\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[500]\ttrain-rmse:0.122318\tvalid-rmse:0.159717\n",
      "[1000]\ttrain-rmse:0.058639\tvalid-rmse:0.123772\n",
      "[1500]\ttrain-rmse:0.053118\tvalid-rmse:0.122553\n",
      "Stopping. Best iteration:\n",
      "[1842]\ttrain-rmse:0.051636\tvalid-rmse:0.122243\n",
      "\n",
      "[0]\ttrain-rmse:11.4254\tvalid-rmse:11.3782\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[500]\ttrain-rmse:0.123251\tvalid-rmse:0.158942\n",
      "[1000]\ttrain-rmse:0.058032\tvalid-rmse:0.121575\n",
      "[1500]\ttrain-rmse:0.052576\tvalid-rmse:0.12016\n",
      "[2000]\ttrain-rmse:0.050404\tvalid-rmse:0.119933\n",
      "Stopping. Best iteration:\n",
      "[2283]\ttrain-rmse:0.04954\tvalid-rmse:0.119712\n",
      "\n",
      "[0]\ttrain-rmse:11.4118\tvalid-rmse:11.4333\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[500]\ttrain-rmse:0.122505\tvalid-rmse:0.159733\n",
      "[1000]\ttrain-rmse:0.058207\tvalid-rmse:0.12748\n",
      "[1500]\ttrain-rmse:0.052858\tvalid-rmse:0.126587\n",
      "Stopping. Best iteration:\n",
      "[1497]\ttrain-rmse:0.05289\tvalid-rmse:0.126555\n",
      "\n",
      "[0]\ttrain-rmse:11.4167\tvalid-rmse:11.414\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[500]\ttrain-rmse:0.123144\tvalid-rmse:0.137581\n",
      "[1000]\ttrain-rmse:0.058741\tvalid-rmse:0.108863\n",
      "Stopping. Best iteration:\n",
      "[853]\ttrain-rmse:0.062821\tvalid-rmse:0.108704\n",
      "\n",
      "[0]\ttrain-rmse:11.4148\tvalid-rmse:11.421\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[500]\ttrain-rmse:0.122665\tvalid-rmse:0.146047\n",
      "[1000]\ttrain-rmse:0.058557\tvalid-rmse:0.108724\n",
      "[1500]\ttrain-rmse:0.053103\tvalid-rmse:0.107977\n",
      "[2000]\ttrain-rmse:0.050827\tvalid-rmse:0.107687\n",
      "Stopping. Best iteration:\n",
      "[2155]\ttrain-rmse:0.050338\tvalid-rmse:0.107603\n",
      "\n",
      "Finished training and predicting...\n"
     ]
    }
   ],
   "source": [
    "xgbpreds = trainxgb(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Bayesian Optimization on LGB...\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   bagging_fraction |   feature_fraction |   lambda_l1 |   lambda_l2 |   max_depth |   min_child_weight |   min_split_gain |   num_leaves | \n",
      "    1 | 00m02s | \u001b[35m  -0.14820\u001b[0m | \u001b[32m            0.8176\u001b[0m | \u001b[32m            0.6552\u001b[0m | \u001b[32m     4.3148\u001b[0m | \u001b[32m     2.8594\u001b[0m | \u001b[32m     7.1991\u001b[0m | \u001b[32m           16.5535\u001b[0m | \u001b[32m          0.0886\u001b[0m | \u001b[32m      8.7493\u001b[0m | \n",
      "    2 | 00m02s | \u001b[35m  -0.14557\u001b[0m | \u001b[32m            0.2087\u001b[0m | \u001b[32m            0.1333\u001b[0m | \u001b[32m     4.2770\u001b[0m | \u001b[32m     0.2219\u001b[0m | \u001b[32m     7.9322\u001b[0m | \u001b[32m           13.1032\u001b[0m | \u001b[32m          0.0395\u001b[0m | \u001b[32m     17.1749\u001b[0m | \n",
      "    3 | 00m03s | \u001b[35m  -0.14112\u001b[0m | \u001b[32m            0.3054\u001b[0m | \u001b[32m            0.7442\u001b[0m | \u001b[32m     2.0477\u001b[0m | \u001b[32m     1.6673\u001b[0m | \u001b[32m     4.3369\u001b[0m | \u001b[32m           10.9463\u001b[0m | \u001b[32m          0.0888\u001b[0m | \u001b[32m     22.4668\u001b[0m | \n",
      "    4 | 00m04s | \u001b[35m  -0.13013\u001b[0m | \u001b[32m            0.7433\u001b[0m | \u001b[32m            0.5315\u001b[0m | \u001b[32m     1.0729\u001b[0m | \u001b[32m     2.5662\u001b[0m | \u001b[32m    10.8915\u001b[0m | \u001b[32m           21.8974\u001b[0m | \u001b[32m          0.0098\u001b[0m | \u001b[32m     14.6074\u001b[0m | \n",
      "    5 | 00m02s |   -0.14640 |             0.6397 |             0.6662 |      4.3987 |      0.1046 |      5.4307 |            23.4137 |           0.0551 |       7.9030 | \n",
      "    6 | 00m02s |   -0.14683 |             0.2501 |             0.3194 |      4.7149 |      2.7712 |      7.4309 |            10.8067 |           0.0559 |      21.3390 | \n",
      "    7 | 00m02s |   -0.13559 |             0.8349 |             0.3975 |      1.7204 |      2.1533 |      5.8334 |            16.6693 |           0.0507 |      10.1495 | \n",
      "    8 | 00m02s |   -0.14126 |             0.7563 |             0.3518 |      3.1817 |      2.7830 |     13.9550 |            24.2335 |           0.0595 |      11.1747 | \n",
      "    9 | 00m03s |   -0.14391 |             0.7312 |             0.7656 |      3.3226 |      0.9516 |      3.8122 |             3.7793 |           0.0509 |      22.2313 | \n",
      "   10 | 00m02s |   -0.13537 |             0.7610 |             0.3357 |      1.5132 |      2.2697 |      3.5243 |             2.1855 |           0.0626 |      20.4580 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m------------------------------------------------------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |   bagging_fraction |   feature_fraction |   lambda_l1 |   lambda_l2 |   max_depth |   min_child_weight |   min_split_gain |   num_leaves | \n",
      "   11 | 00m19s | \u001b[35m  -0.12594\u001b[0m | \u001b[32m            0.8971\u001b[0m | \u001b[32m            0.1762\u001b[0m | \u001b[32m     0.2539\u001b[0m | \u001b[32m     2.1292\u001b[0m | \u001b[32m    14.7721\u001b[0m | \u001b[32m            2.7303\u001b[0m | \u001b[32m          0.0179\u001b[0m | \u001b[32m     23.4738\u001b[0m | \n",
      "   12 | 00m13s | \u001b[35m  -0.12393\u001b[0m | \u001b[32m            0.8404\u001b[0m | \u001b[32m            0.1488\u001b[0m | \u001b[32m     0.0003\u001b[0m | \u001b[32m     2.6001\u001b[0m | \u001b[32m     6.4100\u001b[0m | \u001b[32m           23.9976\u001b[0m | \u001b[32m          0.0041\u001b[0m | \u001b[32m     18.8333\u001b[0m | \n",
      "   13 | 00m09s |   -0.12908 |             0.7325 |             0.3350 |      0.1820 |      1.6946 |     14.1593 |            23.7019 |           0.0611 |      23.7616 | \n",
      "   14 | 00m07s |   -0.12552 |             0.4175 |             0.2953 |      0.0006 |      1.5716 |      3.6677 |            24.5103 |           0.0232 |       9.8777 | \n",
      "   15 | 00m06s |   -0.13023 |             0.7729 |             0.1051 |      0.0242 |      0.9912 |      8.4691 |            24.0839 |           0.0943 |      13.5232 | \n",
      "   16 | 00m11s |   -0.13415 |             0.8392 |             0.8638 |      0.0407 |      0.6255 |     14.7300 |             1.0587 |           0.0919 |      15.2314 | \n",
      "   17 | 00m13s |   -0.12902 |             0.4597 |             0.7660 |      0.1103 |      2.9724 |      3.5491 |            23.5360 |           0.0071 |      12.5888 | \n",
      "   18 | 00m12s |   -0.13711 |             0.2483 |             0.1361 |      0.0183 |      2.6967 |      3.3505 |            22.4557 |           0.0859 |       3.3680 | \n",
      "   19 | 00m17s |   -0.12423 |             0.8749 |             0.3190 |      0.2171 |      2.7520 |     14.0303 |            17.4075 |           0.0079 |      19.0810 | \n",
      "   20 | 00m15s |   -0.13448 |             0.6995 |             0.2414 |      0.1775 |      0.0942 |      3.4474 |             2.0117 |           0.0918 |       3.5468 | \n",
      "   21 | 00m13s |   -0.12841 |             0.8545 |             0.1544 |      0.2038 |      1.0000 |      3.1650 |            23.9121 |           0.0442 |      24.2058 | \n",
      "   22 | 00m13s |   -0.12810 |             0.2636 |             0.2073 |      0.4150 |      2.8551 |     12.8256 |            23.7945 |           0.0367 |      24.0665 | \n",
      "   23 | 00m12s |   -0.12529 |             0.8391 |             0.2759 |      0.0810 |      0.0498 |      3.7634 |             1.1890 |           0.0267 |      14.2770 | \n",
      "   24 | 00m11s |   -0.12558 |             0.7270 |             0.2160 |      0.0893 |      0.2890 |      3.0244 |            21.4714 |           0.0087 |      13.4144 | \n",
      "   25 | 00m10s |   -0.12653 |             0.8986 |             0.1877 |      0.2071 |      0.5915 |      3.1359 |            24.4211 |           0.0173 |       9.7910 | \n",
      "   26 | 00m21s |   -0.12438 |             0.8893 |             0.4467 |      0.0609 |      0.2177 |     11.4312 |             1.6518 |           0.0016 |      24.7923 | \n",
      "   27 | 00m14s |   -0.12566 |             0.4530 |             0.2974 |      0.2197 |      0.3304 |      3.3675 |             1.9226 |           0.0255 |      24.8240 | \n",
      "   28 | 00m13s |   -0.12559 |             0.8914 |             0.2563 |      0.0030 |      2.9975 |     11.7902 |            18.2215 |           0.0309 |      21.5417 | \n",
      "   29 | 00m18s |   -0.12427 |             0.1698 |             0.1592 |      0.0495 |      2.5286 |     14.1393 |            21.1325 |           0.0108 |      17.2659 | \n",
      "   30 | 00m16s | \u001b[35m  -0.12302\u001b[0m | \u001b[32m            0.1203\u001b[0m | \u001b[32m            0.2503\u001b[0m | \u001b[32m     0.0454\u001b[0m | \u001b[32m     0.2664\u001b[0m | \u001b[32m     4.6499\u001b[0m | \u001b[32m            1.3452\u001b[0m | \u001b[32m          0.0040\u001b[0m | \u001b[32m     17.7457\u001b[0m | \n",
      "   31 | 00m14s |   -0.12516 |             0.3894 |             0.1630 |      0.0313 |      2.9643 |     10.7076 |             6.1449 |           0.0249 |      13.7921 | \n",
      "   32 | 00m15s |   -0.12829 |             0.2885 |             0.1195 |      0.1897 |      1.8574 |      3.1622 |            24.5464 |           0.0108 |      11.9592 | \n",
      "   33 | 00m22s |   -0.12785 |             0.4075 |             0.8138 |      0.0821 |      0.1012 |      5.8727 |            15.7703 |           0.0080 |       7.5508 | \n",
      "   34 | 00m20s |   -0.13062 |             0.5213 |             0.5565 |      0.1420 |      2.7132 |     11.1713 |             1.6142 |           0.0553 |      24.8673 | \n",
      "   35 | 00m16s |   -0.13481 |             0.4080 |             0.3307 |      0.2685 |      2.7563 |     14.3695 |             1.9498 |           0.0074 |       3.0791 | \n",
      "   36 | 00m20s |   -0.12725 |             0.1143 |             0.7706 |      0.0289 |      0.7188 |      5.7659 |            24.1768 |           0.0103 |      21.5084 | \n",
      "   37 | 00m22s |   -0.12409 |             0.1425 |             0.4287 |      0.0645 |      2.9222 |     14.3699 |            13.3516 |           0.0095 |      13.0492 | \n",
      "   38 | 00m17s |   -0.12388 |             0.4332 |             0.1715 |      0.1006 |      0.3025 |      4.8035 |             6.8749 |           0.0077 |      18.6791 | \n",
      "   39 | 00m16s |   -0.12850 |             0.1564 |             0.8409 |      0.0518 |      0.0495 |      5.5954 |            23.5914 |           0.0132 |       6.1149 | \n",
      "   40 | 00m16s |   -0.12749 |             0.5715 |             0.2166 |      0.0112 |      0.1706 |      6.7952 |             1.0285 |           0.0597 |      20.5476 | \n",
      "   41 | 00m17s |   -0.12541 |             0.3278 |             0.3875 |      0.0311 |      0.9951 |      3.1028 |            10.8216 |           0.0201 |      12.6780 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   42 | 00m19s |   -0.12572 |             0.5248 |             0.2173 |      0.1155 |      1.4602 |     14.9314 |             9.7043 |           0.0273 |      24.4330 | \n",
      "   43 | 00m20s |   -0.12630 |             0.4075 |             0.1046 |      0.1544 |      2.3286 |      4.0143 |             1.0172 |           0.0041 |      11.7804 | \n",
      "   44 | 00m30s |   -0.12375 |             0.1490 |             0.1667 |      0.0269 |      0.3290 |     14.5353 |             6.6296 |           0.0052 |      22.5266 | \n",
      "   45 | 00m18s |   -0.12852 |             0.3073 |             0.1044 |      0.0761 |      0.0111 |      3.3783 |             3.9546 |           0.0501 |      17.5399 | \n",
      "   46 | 00m29s |   -0.12668 |             0.2499 |             0.8034 |      0.0054 |      1.7909 |      8.6878 |            10.4835 |           0.0031 |      18.4304 | \n",
      "   47 | 00m30s |   -0.12366 |             0.5710 |             0.2162 |      0.0216 |      0.2683 |     10.1743 |             1.9812 |           0.0102 |       8.9550 | \n",
      "   48 | 00m21s |   -0.14562 |             0.4153 |             0.2924 |      4.9217 |      0.5414 |     14.8464 |             1.0636 |           0.0342 |      10.1211 | \n",
      "   49 | 00m22s |   -0.12763 |             0.2885 |             0.8224 |      0.1817 |      0.0131 |      7.2537 |             1.1087 |           0.0133 |      10.4424 | \n",
      "   50 | 00m20s | \u001b[35m  -0.12301\u001b[0m | \u001b[32m            0.6561\u001b[0m | \u001b[32m            0.3108\u001b[0m | \u001b[32m     0.0464\u001b[0m | \u001b[32m     0.1849\u001b[0m | \u001b[32m    13.8265\u001b[0m | \u001b[32m            8.6214\u001b[0m | \u001b[32m          0.0088\u001b[0m | \u001b[32m     12.1426\u001b[0m | \n",
      "   51 | 00m19s |   -0.12476 |             0.2742 |             0.1242 |      0.0016 |      0.1537 |      8.3575 |             7.4638 |           0.0141 |      12.3341 | \n",
      "   52 | 00m18s |   -0.12414 |             0.6576 |             0.1251 |      0.0116 |      1.8974 |     13.3513 |            12.2573 |           0.0013 |      13.9351 | \n",
      "   53 | 00m24s |   -0.12357 |             0.4409 |             0.2756 |      0.1394 |      1.0193 |     14.6088 |             7.8883 |           0.0046 |       9.0712 | \n",
      "   54 | 00m21s |   -0.12418 |             0.5458 |             0.1776 |      0.0499 |      0.2793 |     14.5322 |             2.3037 |           0.0012 |      24.2702 | \n",
      "   55 | 00m18s |   -0.12333 |             0.7632 |             0.1746 |      0.0081 |      2.9582 |     14.9167 |             5.7453 |           0.0012 |      14.1010 | \n",
      "   56 | 00m16s |   -0.12539 |             0.8294 |             0.2588 |      0.1026 |      0.2964 |      3.2274 |            18.4552 |           0.0124 |      24.6260 | \n",
      "   57 | 00m18s |   -0.12384 |             0.7635 |             0.2379 |      0.0050 |      2.8174 |     11.0060 |            23.2218 |           0.0123 |      24.7345 | \n",
      "   58 | 00m18s |   -0.12308 |             0.5875 |             0.2578 |      0.0070 |      0.7448 |      5.5545 |             7.5502 |           0.0068 |      23.2900 | \n",
      "   59 | 00m16s |   -0.12373 |             0.7008 |             0.1571 |      0.0113 |      0.4029 |      4.4642 |            14.2785 |           0.0071 |      15.4650 | \n",
      "   60 | 00m13s |   -0.12328 |             0.2639 |             0.2123 |      0.0125 |      0.6531 |     13.4029 |             6.3920 |           0.0090 |      14.5033 | \n",
      "Identified optimal hyperparameters...\n",
      "Maximum value obtained: -0.12301416384255197\n",
      "{'num_leaves': 12.142629973554964, 'feature_fraction': 0.3108386357744111, 'bagging_fraction': 0.65614551729273, 'max_depth': 13.826456730410065, 'lambda_l1': 0.046389474157008115, 'lambda_l2': 0.18486882436062224, 'min_split_gain': 0.00881695646192963, 'min_child_weight': 8.621433429727025}\n"
     ]
    }
   ],
   "source": [
    "params = lgbBayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LightGBM with found parameters...\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\tvalid_0's rmse: 0.134223\n",
      "[1000]\tvalid_0's rmse: 0.130256\n",
      "Early stopping, best iteration is:\n",
      "[978]\tvalid_0's rmse: 0.130229\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\tvalid_0's rmse: 0.130828\n",
      "[1000]\tvalid_0's rmse: 0.12613\n",
      "Early stopping, best iteration is:\n",
      "[1039]\tvalid_0's rmse: 0.126091\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\tvalid_0's rmse: 0.134153\n",
      "[1000]\tvalid_0's rmse: 0.129058\n",
      "Early stopping, best iteration is:\n",
      "[1098]\tvalid_0's rmse: 0.129017\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\tvalid_0's rmse: 0.121448\n",
      "[1000]\tvalid_0's rmse: 0.118543\n",
      "Early stopping, best iteration is:\n",
      "[909]\tvalid_0's rmse: 0.118413\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[500]\tvalid_0's rmse: 0.113089\n",
      "[1000]\tvalid_0's rmse: 0.107368\n",
      "Early stopping, best iteration is:\n",
      "[1147]\tvalid_0's rmse: 0.107021\n",
      "Finished training and predicting...\n"
     ]
    }
   ],
   "source": [
    "lgbpreds = trainlgb(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
