{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readdata():\n",
    "    train = pd.read_csv(\"train.csv\")\n",
    "    print('Shape of train: {}'.format(train.shape))\n",
    "    test = pd.read_csv(\"test.csv\")\n",
    "    print('Shape of test: {}'.format(test.shape))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (1460, 81)\n",
      "Shape of test: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "train, test = readdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparedata():\n",
    "    train, test = readdata()\n",
    "    print(\"Preparing data....\")\n",
    "    print(\"Log-transforming target....\")\n",
    "    train[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])\n",
    "    \n",
    "    print(\"Combining datasets...\")\n",
    "    trainrow = train.shape[0]\n",
    "    testrow = test.shape[0]\n",
    "    \n",
    "    train_ID = train['Id']\n",
    "    test_ID = test['Id']\n",
    "    train.drop('Id', axis=1, inplace=True)\n",
    "    test.drop('Id', axis = 1, inplace = True)\n",
    "    \n",
    "    print(\"Saving target...\")\n",
    "    target = train.SalePrice.values\n",
    "    \n",
    "    all_data = pd.concat((train,test)).reset_index(drop=True)\n",
    "    all_data.drop(['SalePrice'], axis=1, inplace=True)\n",
    "    \n",
    "    print(\"Combined datasize is : {}\".format(all_data.shape))\n",
    "    \n",
    "    print(\"Filling Categorical NA's...\")\n",
    "    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', 'SaleType','MiscFeature', 'Alley',\n",
    "            'BsmtExposure', 'BsmtCond','BsmtFinType2', 'BsmtFinType1', 'MasVnrType','MSZoning', 'PoolQC', 'Fence', 'FireplaceQu'):\n",
    "        all_data[col] = all_data[col].fillna('Unknown')\n",
    "        \n",
    "    print(\"Filling Numerical NA's...\")\n",
    "    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea', 'BsmtHalfBath', 'BsmtFullBath', 'BsmtFinSF1',\n",
    "           'BsmtFinSF1', 'TotalBsmtSF', 'BsmtUnfSF', 'BsmtFinSF2'):\n",
    "            all_data[col] = all_data[col].fillna(0)\n",
    "    \n",
    "    print(\"Imputing with median...\")\n",
    "    all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    print(\"Imputing with mode...\")\n",
    "    all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
    "    all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
    "    all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
    "    all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
    "    all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
    "    \n",
    "    print(\"Dropping features...\")\n",
    "    all_data = all_data.drop(['Utilities'], axis=1)\n",
    "    \n",
    "    print(\"Labelencoding Categorical Features...\")\n",
    "    catcols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
    "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
    "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
    "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
    "        'YrSold', 'MoSold')\n",
    "    for c in catcols:\n",
    "        lbl = LabelEncoder() \n",
    "        lbl.fit(list(all_data[c].values)) \n",
    "        all_data[c] = lbl.transform(list(all_data[c].values))\n",
    "        \n",
    "    print(\"One-hot Encoding Categorical Variables...\")\n",
    "    all_data = pd.get_dummies(all_data)\n",
    "        \n",
    "        \n",
    "    print('Final shape of dataset: {}'.format(all_data.shape))\n",
    "    print(\"Splitting dataset and returning train, test and target...\")\n",
    "    train = all_data[:trainrow] \n",
    "    test = all_data[trainrow:]\n",
    "    \n",
    "    return train, test, target, test_ID\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train: (1460, 81)\n",
      "Shape of test: (1459, 80)\n",
      "Preparing data....\n",
      "Log-transforming target....\n",
      "Combining datasets...\n",
      "Saving target...\n",
      "Combined datasize is : (2919, 79)\n",
      "Filling Categorical NA's...\n",
      "Filling Numerical NA's...\n",
      "Imputing with median...\n",
      "Imputing with mode...\n",
      "Dropping features...\n",
      "Labelencoding Categorical Features...\n",
      "One-hot Encoding Categorical Variables...\n",
      "Final shape of dataset: (2919, 223)\n",
      "Splitting dataset and returning train, test and target...\n"
     ]
    }
   ],
   "source": [
    "train, test, target, test_ID = preparedata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 223)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 223)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460,)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BayesXGB():\n",
    "    print(\"Preparing dataset for Bayesian optimization of XGBoost hyperparameters...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20)\n",
    "    dtrain =xgb.DMatrix(X_train, label=y_train)\n",
    "    dtest = xgb.DMatrix(X_test)\n",
    "    \n",
    "    print(\"Performing Bayesian Optimization...\")\n",
    "    xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth'       : (3,15),\n",
    "                                                 'gamma'           : (0,5),\n",
    "                                                'colsample_bytree' : (0.3, 0.9),\n",
    "                                                'min_child_weight' : (0,25),\n",
    "                                                 'subsample'       : (0.5, 1),\n",
    "                                                 'alpha'           : (0, 5)\n",
    "                                            })\n",
    "    xgb_bo.maximize(init_points=2, n_iter=5, acq = 'ei')\n",
    "    \n",
    "    print(xgb_bo.res['max'])\n",
    "    params = (xgb_bo.res['max']['max_params'])\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    params['min_child_weight'] = int(params['min_child_weight'])\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20)\n",
    "dtrain =xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_evaluate(max_depth, gamma, colsample_bytree, min_child_weight, subsample, alpha):\n",
    "    params = {\n",
    "        'eval_metric' : 'rmse',\n",
    "        'max_depth'   : int(max_depth),\n",
    "        'subsample'   : max(min(subsample,1),0) ,\n",
    "        'eta'         : 0.1 ,\n",
    "        'gamma'       : max(gamma,0),\n",
    "        'alpha'       : max(alpha, 0),\n",
    "        'colsample_bytree' : max(min(colsample_bytree,1),0),\n",
    "        'min_child_weight' : int(min_child_weight)\n",
    "    }\n",
    "    cv_result = xgb.cv(params, dtrain, num_boost_round = 1000, early_stopping_rounds = 100, nfold=5)\n",
    "    #BayesOptimization kan kun maximere og ikke minimere, derfor skal vi g√∏re RMSE negativt\n",
    "    return -1 * cv_result['test-rmse-mean'].iloc[-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(xgb_evaluate, {'max_depth'       : (3,15),\n",
    "                                             'gamma'           : (0,5),\n",
    "                                            'colsample_bytree' : (0.3, 0.9),\n",
    "                                            'min_child_weight' : (0,25),\n",
    "                                             'subsample'       : (0.5, 1),\n",
    "                                             'alpha'           : (0, 5)\n",
    "                                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset for Bayesian optimization of XGBoost hyperparameters...\n",
      "Performing Bayesian Optimization...\n",
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 00m12s | \u001b[35m  -0.18731\u001b[0m | \u001b[32m   0.3266\u001b[0m | \u001b[32m            0.6059\u001b[0m | \u001b[32m   2.5303\u001b[0m | \u001b[32m     6.5262\u001b[0m | \u001b[32m           16.4276\u001b[0m | \u001b[32m     0.9954\u001b[0m | \n",
      "    2 | 00m17s |   -0.20663 |    4.3918 |             0.7762 |    3.3778 |     14.8957 |            12.1164 |      0.6624 | \n"
     ]
    }
   ],
   "source": [
    "params = BayesXGB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mInitialization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "    1 | 00m58s | \u001b[35m  -0.18050\u001b[0m | \u001b[32m   1.9113\u001b[0m | \u001b[32m            0.4778\u001b[0m | \u001b[32m   1.9718\u001b[0m | \u001b[32m    14.4089\u001b[0m | \u001b[32m            1.7665\u001b[0m | \u001b[32m     0.7602\u001b[0m | \n",
      "    2 | 00m14s |   -0.21009 |    1.6834 |             0.3393 |    4.6990 |      6.6876 |             2.1434 |      0.8696 | \n",
      "    3 | 00m27s | \u001b[35m  -0.17921\u001b[0m | \u001b[32m   3.0821\u001b[0m | \u001b[32m            0.3889\u001b[0m | \u001b[32m   1.7865\u001b[0m | \u001b[32m    14.8938\u001b[0m | \u001b[32m           18.6927\u001b[0m | \u001b[32m     0.8969\u001b[0m | \n",
      "    4 | 00m13s |   -0.18707 |    2.8926 |             0.5000 |    2.1073 |      7.0058 |            20.1832 |      0.6816 | \n",
      "    5 | 00m17s |   -0.20311 |    0.2802 |             0.6106 |    4.4314 |     14.8441 |            14.6582 |      0.9027 | \n",
      "    6 | 00m11s |   -0.20385 |    3.8359 |             0.8883 |    3.2157 |      5.5072 |            16.4997 |      0.6616 | \n",
      "    7 | 00m17s | \u001b[35m  -0.15990\u001b[0m | \u001b[32m   1.7330\u001b[0m | \u001b[32m            0.5994\u001b[0m | \u001b[32m   0.8768\u001b[0m | \u001b[32m     9.0356\u001b[0m | \u001b[32m           24.8475\u001b[0m | \u001b[32m     0.9521\u001b[0m | \n",
      "    8 | 00m07s |   -0.21217 |    2.0135 |             0.4679 |    4.4533 |     11.1128 |            14.2550 |      0.7325 | \n",
      "    9 | 00m10s | \u001b[35m  -0.15837\u001b[0m | \u001b[32m   2.8601\u001b[0m | \u001b[32m            0.3093\u001b[0m | \u001b[32m   0.6426\u001b[0m | \u001b[32m     4.5923\u001b[0m | \u001b[32m            2.6743\u001b[0m | \u001b[32m     0.9805\u001b[0m | \n",
      "   10 | 00m25s |   -0.17093 |    0.4280 |             0.5989 |    1.6299 |     13.6105 |            17.5405 |      0.8340 | \n",
      "\u001b[31mBayesian Optimization\u001b[0m\n",
      "\u001b[94m---------------------------------------------------------------------------------------------------------------------------\u001b[0m\n",
      " Step |   Time |      Value |     alpha |   colsample_bytree |     gamma |   max_depth |   min_child_weight |   subsample | \n",
      "   11 | 00m19s | \u001b[35m  -0.12730\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m            0.9000\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m     3.0000\u001b[0m | \u001b[32m            0.0000\u001b[0m | \u001b[32m     1.0000\u001b[0m | \n",
      "   12 | 00m27s |   -0.13300 |    1.0810 |             0.8406 |    0.0102 |     14.7780 |            24.7438 |      0.5494 | \n",
      "   13 | 00m18s |   -0.13022 |    1.3147 |             0.6908 |    0.0264 |      3.1713 |             0.1631 |      0.5887 | \n",
      "   14 | 00m11s |   -0.13010 |    0.5611 |             0.8407 |    0.0099 |      3.2986 |             1.5985 |      0.5299 | \n",
      "   15 | 00m36s |   -0.13015 |    0.3113 |             0.7063 |    0.0394 |      6.4180 |             0.7824 |      0.5092 | \n",
      "   16 | 00m14s |   -0.13287 |    0.0208 |             0.8303 |    0.0426 |      3.4290 |             0.0343 |      0.5012 | \n",
      "   17 | 00m55s |   -0.14697 |    4.2374 |             0.8651 |    0.0250 |      7.5843 |             0.6510 |      0.9117 | \n",
      "   18 | 01m15s |   -0.13326 |    0.1748 |             0.8719 |    0.0192 |     12.8024 |             0.2885 |      0.6771 | \n",
      "   19 | 00m39s |   -0.14110 |    4.7147 |             0.7864 |    0.0175 |     13.1696 |            24.9868 |      0.9264 | \n",
      "   20 | 00m37s |   -0.13640 |    0.9738 |             0.8551 |    0.0575 |      4.7108 |             0.3391 |      0.9268 | \n",
      "   21 | 00m13s | \u001b[35m  -0.12595\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m            0.3009\u001b[0m | \u001b[32m   0.0000\u001b[0m | \u001b[32m     3.0454\u001b[0m | \u001b[32m           15.0997\u001b[0m | \u001b[32m     0.5000\u001b[0m | \n",
      "   22 | 00m27s |   -0.13220 |    0.0714 |             0.5068 |    0.0705 |     10.8123 |             5.4003 |      0.7235 | \n",
      "   23 | 00m31s |   -0.13333 |    0.5226 |             0.7180 |    0.1291 |      3.0240 |            24.2613 |      0.6138 | \n",
      "   24 | 00m37s |   -0.13002 |    0.1367 |             0.3420 |    0.0333 |      9.7752 |             0.6681 |      0.5122 | \n",
      "   25 | 00m21s |   -0.20834 |    0.3257 |             0.7548 |    4.9459 |      3.1276 |            24.0574 |      0.7498 | \n",
      "   26 | 00m30s |   -0.13152 |    0.1222 |             0.8282 |    0.0479 |      3.0074 |            11.2730 |      0.9408 | \n",
      "   27 | 00m13s |   -0.15509 |    4.9719 |             0.6448 |    0.1984 |      3.5886 |            24.4217 |      0.6740 | \n",
      "   28 | 00m17s |   -0.13179 |    0.1307 |             0.8124 |    0.0755 |      3.1688 |            20.3843 |      0.7105 | \n",
      "   29 | 00m19s |   -0.13221 |    0.0855 |             0.8834 |    0.0135 |      8.7500 |             4.2805 |      0.6902 | \n",
      "   30 | 00m42s |   -0.13302 |    0.0729 |             0.7280 |    0.0929 |     14.5074 |             6.6549 |      0.5226 | \n",
      "   31 | 00m24s |   -0.14531 |    4.9900 |             0.7464 |    0.0241 |      3.5421 |             0.7807 |      0.5331 | \n",
      "   32 | 00m46s |   -0.14898 |    4.9395 |             0.8344 |    0.0092 |     14.4729 |             0.0053 |      0.8324 | \n",
      "   33 | 00m10s |   -0.12778 |    0.1137 |             0.5301 |    0.0195 |      3.2622 |             2.1157 |      0.8293 | \n",
      "   34 | 00m12s |   -0.22890 |    4.7280 |             0.4405 |    4.5733 |     14.9239 |            24.8598 |      0.5181 | \n",
      "   35 | 00m19s |   -0.13177 |    0.0048 |             0.7574 |    0.0386 |     14.6211 |            10.5880 |      0.5356 | \n",
      "   36 | 00m39s |   -0.14624 |    4.7843 |             0.6622 |    0.0419 |     14.3322 |            11.7870 |      0.5467 | \n",
      "   37 | 00m23s |   -0.13482 |    2.8040 |             0.3734 |    0.0194 |      3.1024 |            18.6055 |      0.9023 | \n",
      "   38 | 00m18s |   -0.13180 |    0.3700 |             0.3798 |    0.0295 |     14.9545 |            24.0758 |      0.9908 | \n",
      "   39 | 00m09s |   -0.12917 |    0.0437 |             0.3324 |    0.0428 |      3.3807 |            18.7070 |      0.9190 | \n",
      "   40 | 00m11s |   -0.12797 |    0.1479 |             0.4177 |    0.0083 |      3.1094 |             4.7055 |      0.8200 | \n",
      "   41 | 00m12s |   -0.12907 |    0.0429 |             0.3045 |    0.0370 |     13.9457 |            24.5960 |      0.6247 | \n",
      "   42 | 00m15s |   -0.12795 |    0.4487 |             0.3066 |    0.0187 |      9.2212 |             9.9793 |      0.5093 | \n",
      "   43 | 00m19s |   -0.13043 |    0.0400 |             0.3321 |    0.0245 |     11.3098 |            11.9780 |      0.6760 | \n",
      "   44 | 00m26s |   -0.14894 |    3.2948 |             0.3304 |    0.1928 |     14.9746 |            24.8666 |      0.5590 | \n",
      "   45 | 00m25s |   -0.14410 |    4.4036 |             0.5539 |    0.0531 |      3.0192 |            12.0781 |      0.5321 | \n",
      "   46 | 00m15s |   -0.13194 |    0.3276 |             0.8072 |    0.0083 |     13.6589 |            22.6287 |      0.5171 | \n",
      "   47 | 00m10s |   -0.12709 |    0.1230 |             0.3460 |    0.0515 |      3.0291 |            22.5678 |      0.6570 | \n",
      "   48 | 00m30s |   -0.13327 |    0.1225 |             0.8946 |    0.0590 |     11.9541 |            10.0534 |      0.7099 | \n",
      "   49 | 00m12s |   -0.13136 |    0.1246 |             0.4156 |    0.0099 |      8.0352 |            14.6601 |      0.5702 | \n",
      "   50 | 00m10s |   -0.12954 |    0.0303 |             0.5574 |    0.0271 |      3.0155 |            23.0969 |      0.9318 | \n",
      "   51 | 00m28s |   -0.14380 |    4.8803 |             0.7333 |    0.0209 |     10.4946 |            17.1051 |      0.5737 | \n",
      "   52 | 00m08s |   -0.12827 |    0.7244 |             0.3730 |    0.0094 |      3.2865 |            10.7478 |      0.6061 | \n",
      "   53 | 00m17s |   -0.13250 |    0.0367 |             0.7807 |    0.0438 |     11.2639 |            24.5981 |      0.7564 | \n",
      "   54 | 00m09s |   -0.12746 |    0.4830 |             0.3017 |    0.0222 |      3.0611 |            17.8395 |      0.6092 | \n",
      "   55 | 00m10s |   -0.13065 |    0.0268 |             0.5492 |    0.0322 |      5.7297 |            24.5630 |      0.6410 | \n",
      "   56 | 00m09s |   -0.13053 |    0.1085 |             0.3772 |    0.0052 |      5.1576 |            10.6554 |      0.6404 | \n",
      "   57 | 00m39s |   -0.13190 |    0.4883 |             0.8743 |    0.0034 |     12.5894 |             2.9469 |      0.5281 | \n",
      "   58 | 00m10s |   -0.13163 |    0.1985 |             0.5730 |    0.0310 |      3.0660 |             8.7570 |      0.5066 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   59 | 00m12s |   -0.12802 |    0.3346 |             0.3094 |    0.0041 |      3.0853 |             1.9297 |      0.7528 | \n",
      "   60 | 00m08s |   -0.12874 |    0.1203 |             0.3495 |    0.0217 |      3.0514 |            11.2338 |      0.8327 | \n"
     ]
    }
   ],
   "source": [
    "xgb_bo.maximize(init_points=10, n_iter=50, acq = 'ei')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_val': -0.12594660000000002,\n",
       " 'max_params': {'max_depth': 3.0453557484746963,\n",
       "  'gamma': 0.0,\n",
       "  'colsample_bytree': 0.3009097674964732,\n",
       "  'min_child_weight': 15.0997079744375,\n",
       "  'subsample': 0.5000000001922376,\n",
       "  'alpha': 1.3950466145869655e-10}}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_bo.res['max']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (xgb_bo.res['max']['max_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "params['max_depth'] = int(params['max_depth'])\n",
    "params['min_child_weight'] = int(params['min_child_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'gamma': 0.0,\n",
       " 'colsample_bytree': 0.3009097674964732,\n",
       " 'min_child_weight': 15,\n",
       " 'subsample': 0.5000000001922376,\n",
       " 'alpha': 1.3950466145869655e-10}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainxgb(params):\n",
    "    n_iters = 5\n",
    "    xgb_preds = []\n",
    "    \n",
    "    for i in range(n_iters):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20, random_state = i)\n",
    "    \n",
    "        dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "        dvalid = xgb.DMatrix(X_test, label = y_test)\n",
    "        testxgb   = xgb.DMatrix(test)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "    \n",
    "        xgb_model = xgb.train(params, dtrain, 2000, watchlist, early_stopping_rounds = 150, verbose_eval = 200)\n",
    "        preds = xgb_model.predict(testxgb)\n",
    "        preds = np.exp(preds) - 1\n",
    "        xgb_preds.append(preds)\n",
    "        \n",
    "    predictions = pd.DataFrame(list(zip(np.mean(xgb_preds, axis=0))), columns=['xgbpreds'])\n",
    "    \n",
    "    return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:8.07528\tvalid-rmse:8.07813\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[200]\ttrain-rmse:0.067258\tvalid-rmse:0.149589\n",
      "[400]\ttrain-rmse:0.043806\tvalid-rmse:0.146474\n",
      "[600]\ttrain-rmse:0.030539\tvalid-rmse:0.146779\n",
      "Stopping. Best iteration:\n",
      "[520]\ttrain-rmse:0.035225\tvalid-rmse:0.145243\n",
      "\n",
      "[0]\ttrain-rmse:8.09094\tvalid-rmse:8.04411\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[200]\ttrain-rmse:0.06344\tvalid-rmse:0.145283\n",
      "Stopping. Best iteration:\n",
      "[53]\ttrain-rmse:0.105892\tvalid-rmse:0.138679\n",
      "\n",
      "[0]\ttrain-rmse:8.08045\tvalid-rmse:8.10217\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[200]\ttrain-rmse:0.067126\tvalid-rmse:0.13787\n",
      "Stopping. Best iteration:\n",
      "[137]\ttrain-rmse:0.079739\tvalid-rmse:0.135993\n",
      "\n",
      "[0]\ttrain-rmse:8.08886\tvalid-rmse:8.08547\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "[200]\ttrain-rmse:0.069937\tvalid-rmse:0.137805\n",
      "[400]\ttrain-rmse:0.045242\tvalid-rmse:0.136241\n",
      "Stopping. Best iteration:\n",
      "[373]\ttrain-rmse:0.048506\tvalid-rmse:0.134056\n",
      "\n",
      "[0]\ttrain-rmse:8.08343\tvalid-rmse:8.0892\n",
      "Multiple eval metrics have been passed: 'valid-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid-rmse hasn't improved in 150 rounds.\n",
      "Stopping. Best iteration:\n",
      "[49]\ttrain-rmse:0.110353\tvalid-rmse:0.13207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_iters = 5\n",
    "xgb_preds = []\n",
    "for i in range(n_iters):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=0.20, random_state = i)\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "    dvalid = xgb.DMatrix(X_test, label = y_test)\n",
    "    testxgb   = xgb.DMatrix(test)\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "    \n",
    "    xgb_model = xgb.train(params, dtrain, 2000, watchlist, early_stopping_rounds = 150, verbose_eval = 200)\n",
    "    preds = xgb_model.predict(testxgb)\n",
    "    preds = np.exp(preds) - 1\n",
    "    xgb_preds.append(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(list(zip(np.mean(xgb_preds, axis=0))),\n",
    "              columns=['xgbpreds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xgbpreds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118745.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156308.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>186033.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194516.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>187035.828125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        xgbpreds\n",
       "0  118745.140625\n",
       "1  156308.437500\n",
       "2  186033.015625\n",
       "3  194516.687500\n",
       "4  187035.828125"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test_ID\n",
    "submission[\"SalePrice\"] = predictions['xgbpreds']\n",
    "submission.head()\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(pred):\n",
    "    submission = pd.Dataframe()\n",
    "    submission['Id'] = test_ID\n",
    "    submission['SalePrice'] = pred['xgbpreds']\n",
    "    submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
